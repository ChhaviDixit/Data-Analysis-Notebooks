{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> web\n",
      "web\n",
      "> weeb\n",
      "web\n",
      "> mm\n",
      "NO SUGGESTION\n",
      "> miin\n",
      "NO SUGGESTION\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import math\n",
    "import pandas as pd\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.children = dict()\n",
    "        self.end = False # indicates if this is an exit node\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key in self.children:\n",
    "            return self.children[key]\n",
    "        return None\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.children[key] = value\n",
    "   \n",
    "    def __contains__(self, value):\n",
    "        return value in self.children\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.value)\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = Node('')\n",
    "\n",
    "    def add(self, word):\n",
    "        word = word.strip()\n",
    "        n = self.root\n",
    "        for l in word:\n",
    "            nxt = n[l]\n",
    "            if nxt is not None:\n",
    "                n = nxt\n",
    "            else:\n",
    "                n[l] = Node(l)\n",
    "                n = n[l]\n",
    "        n.end = True\n",
    "\n",
    "    def __contains__(self, word):\n",
    "        n = self.root\n",
    "        for l in word:\n",
    "            if l not in n:\n",
    "                return False\n",
    "            n = n[l]\n",
    "        if n.end == True:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "class SpellCheck:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.words = Trie()\n",
    "        with open('words1.txt','r') as f:\n",
    "            for word in f:\n",
    "                self.words.add(word)\n",
    "        with open('words2.txt','r') as g:\n",
    "            for word in g:\n",
    "                self.words.add(word)\n",
    "\n",
    "    def spellcheck(self, word):\n",
    "       \n",
    "        if word in self.words:\n",
    "            return word\n",
    "\n",
    "        word = word.lower()\n",
    "        if word in self.words:\n",
    "            return word\n",
    "\n",
    "        vowels = 'aeiou'\n",
    "\n",
    "        def recurse(path, word, node):\n",
    "           \n",
    "            if node is None:\n",
    "                return None\n",
    "            if word == '':\n",
    "                if node.end == True:\n",
    "                    return path\n",
    "                if node.end == False:\n",
    "                    return None\n",
    "            ltr = word[0]\n",
    "            if ltr in node:\n",
    "                result = recurse(path + ltr, word[1:], node[ltr])\n",
    "                if result:\n",
    "                    return result\n",
    "            ltr = ltr.lower()\n",
    "            if ltr in node:\n",
    "                result = recurse(path + ltr, word[1:], node[ltr])\n",
    "                if result:\n",
    "                    return result\n",
    "            if len(word) > 1 and ltr == word[1]:\n",
    "                result = recurse(path, word[1:], node)\n",
    "                if result:\n",
    "                    return result\n",
    "\n",
    "            # try replacing vowels\n",
    "            if ltr in vowels:\n",
    "                for v in vowels:\n",
    "                    if v != ltr:\n",
    "                        result = recurse(path + v, word[1:], node[v])\n",
    "                        if result:\n",
    "                            return result\n",
    "\n",
    "            return None\n",
    "\n",
    "        result = recurse('', word, self.words.root)\n",
    "        if result:\n",
    "            return result\n",
    "        return 'NO SUGGESTION'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "   \n",
    "    term=[]\n",
    "    url=\"https://en.wikipedia.org/wiki/Web_mining\"\n",
    "    html=request.urlopen(url).read().decode('utf8')\n",
    "    soup1=BeautifulSoup(html, 'html.parser')\n",
    "    l1=[]\n",
    "    term1=[]\n",
    "    for titles in soup1.find_all(['h1', 'h2','h3','h4','h5','h6', 'p']):\n",
    "        l1=word_tokenize(titles.text)\n",
    "        term1=term1+l1\n",
    "    term.append(term1)\n",
    "       \n",
    "    url=\"https://en.wikipedia.org/wiki/Data_mining\"\n",
    "    html=request.urlopen(url).read().decode('utf8')\n",
    "    soup2=BeautifulSoup(html, 'html.parser')\n",
    "    l2=[]\n",
    "    term2=[]\n",
    "    for titles in soup2.find_all(['h1', 'h2','h3','h4','h5','h6', 'p']):\n",
    "        l2=word_tokenize(titles.text)\n",
    "        term2=term2+l2\n",
    "    term.append(term2)\n",
    "   \n",
    "    stop_words=list(set(stopwords.words('english')))\n",
    "    stop_words_add=[ ',','.', '-', '(', ')', '[', ']', ':', ';', '\\'','&','_']\n",
    "    for words in stop_words_add:\n",
    "        stop_words.extend(words)\n",
    "   \n",
    "    final_term_stop=[]\n",
    "    for i in term:\n",
    "        final=[]\n",
    "        for w in i:\n",
    "            if w not in stop_words:\n",
    "                w=w.lower()\n",
    "                final.append(w)\n",
    "        final_term_stop.append(final)\n",
    "   \n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    final_term=[]\n",
    "    for i in final_term_stop:\n",
    "        lemm=[]\n",
    "        for w in i:\n",
    "            lemm.append(lemmatizer.lemmatize(w))\n",
    "        final_term.append(lemm)\n",
    "   \n",
    "    fopen=open('words1.txt','w', encoding='utf-8')\n",
    "    for element in final_term[0]:\n",
    "        fopen.write(element)\n",
    "        fopen.write('\\n')\n",
    "    fopen.close()\n",
    "    fopen=open('words2.txt','w', encoding='utf-8')\n",
    "    for element in final_term[1]:\n",
    "        fopen.write(element)\n",
    "        fopen.write('\\n')\n",
    "    fopen.close()\n",
    "    if len(sys.argv) > 1 and sys.argv[1] == '-t':\n",
    "        t = Trie()\n",
    "        # Test trie\n",
    "        with open('/usr/share/dict/words','r') as f:\n",
    "            for word in f:\n",
    "                word = word.strip()\n",
    "                t.add(word)\n",
    "                try:\n",
    "                    assert(word in t)\n",
    "                except AssertionError:\n",
    "                    print(word, \"not in trie\")\n",
    "                    sys.exit(1)\n",
    "       \n",
    "        # Run doctests\n",
    "        s = SpellCheck()\n",
    "        import doctest\n",
    "        doctest.testmod(extraglobs={'s': s })\n",
    "        sys.exit(0)\n",
    "\n",
    "    s = SpellCheck()\n",
    "    c=0\n",
    "    while c==0:\n",
    "        word = input('Enter a word: ')\n",
    "        print(s.spellcheck(word))\n",
    "        l=input('Would you like to check another word? yes/no: ' )\n",
    "        if inputchoice=='yes':\n",
    "            c=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
