{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of sentences in the summary: 2\n",
      " लेकिन उस दिन उसके पास ज्यादा पैसे नहीं थे, ऐसे में वह मिठाई खरीद नहीं सकता था, तब वह कुछ देर वहीं खड़े होकर मिठाइयों की सुगंध का आनंद लेने लगा\n",
      " ऐसे में जब वह हलवाई की दुकान के पास से गुजरा तो उसे मिठाइयों की खुशबू आने लगी\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "\n",
    "st=['के','का',',','में','की','है','यह','थे','ही','और','से','हैं','थी','को','पर','इस','होता','कि','जो','कर','मे','गया','करने','किया','लिये','अपने','ने','बनी','नहीं','तो','ही','या',\"एवं\",'दिया','हो','इसका','था','ही','द्वारा','हुआ','तक','साथ','करना','वाले','बाद','लिए','आप','कुछ','सकते','किसी','ये','इसके','सबसे','इसमें','थे','दो','होने','वह','वे','करते','बहुत','कहा','वर्ग','कई','करें','होती','अपनी','उनके','थी','यदि','हुई','जा','ना','इसे','कहते','जब','होते','कोई','हुए','व','न','अभी','जैसे','सभी','करता','उनकी','तरह','उस','आदि','कुल','एस','रहा','इसकी','सकता','रहे','उनका','इसी','रखें','अपना','पे','उसके']\n",
    "s='एक किसान था, वह अपने खेतों में काम कर घर लौट रहा था। रास्ते में ही एक हलवाई की दुकान थी। उस दिन किसान ने कुछ ज्‍यादा काम कर लिया था और उसे भूख भी बहुत लग रही थी। ऐसे में जब वह हलवाई की दुकान के पास से गुजरा तो उसे मिठाइयों की खुशबू आने लगी। वह वहां खुद को रोके बिना नहीं रह पाया। लेकिन उस दिन उसके पास ज्यादा पैसे नहीं थे, ऐसे में वह मिठाई खरीद नहीं सकता था, तब वह कुछ देर वहीं खड़े होकर मिठाइयों की सुगंध का आनंद लेने लगा।'\n",
    "new=[]\n",
    "ne=[]\n",
    "ovr=[]\n",
    "a=s.split('।')\n",
    "for i in a:\n",
    "    ne.append(word_tokenize(i))\n",
    "for j in ne:\n",
    "    for i in j:\n",
    "        if '।' not in i and i not in [',','?','!']:        \n",
    "            t=i\n",
    "            if t not in st:\n",
    "                new.append(i)\n",
    "    ovr.append(new)\n",
    "    new=[]\n",
    "\n",
    "suffixes = {\n",
    "    1: [\"ो\", \"े\", \"ू\", \"ु\", \"ी\", \"ि\", \"ा\"],\n",
    "    2: [\"कर\", \"ाओ\", \"िए\", \"ाई\", \"ाए\", \"ने\", \"नी\", \"ना\", \"ते\", \"ीं\", \"ती\", \"ता\", \"ाँ\", \"ां\", \"ों\", \"ें\"],\n",
    "    3: [\"ाकर\", \"ाइए\", \"ाईं\", \"ाया\", \"ेगी\", \"ेगा\", \"ोगी\", \"ोगे\", \"ाने\", \"ाना\", \"ाते\", \"ाती\", \"ाता\", \"तीं\", \"ाओं\", \"ाएं\", \"ुओं\", \"ुएं\", \"ुआं\"],\n",
    "    4: [\"ाएगी\", \"ाएगा\", \"ाओगी\", \"ाओगे\", \"एंगी\", \"ेंगी\", \"एंगे\", \"ेंगे\", \"ूंगी\", \"ूंगा\", \"ातीं\", \"नाओं\", \"नाएं\", \"ताओं\", \"ताएं\", \"ियाँ\", \"ियों\", \"ियां\"],\n",
    "    5: [\"ाएंगी\", \"ाएंगे\", \"ाऊंगी\", \"ाऊंगा\", \"ाइयाँ\", \"ाइयों\", \"ाइयां\"],\n",
    "}\n",
    "lemm=[]\n",
    "lemm_f=[]\n",
    "for new in ovr:\n",
    "    for word in new:\n",
    "        c=0\n",
    "        for L in 5, 4, 3, 2, 1:\n",
    "            if len(word)>L+1:\n",
    "                for suf in suffixes[L]:\n",
    "                    if word.endswith(suf):\n",
    "                        c=1\n",
    "                        lemm.append(word[:-L])\n",
    "                        break\n",
    "                if c==1:\n",
    "                    break\n",
    "        if c==0:\n",
    "            lemm.append(word)\n",
    "    lemm_f.append(lemm)\n",
    "    lemm=[]\n",
    "\n",
    "import math\n",
    "idf={}\n",
    "uni=[]\n",
    "freqTable = dict() \n",
    "for lemm in lemm_f:\n",
    "    for word in lemm: \n",
    "        if word not in uni:\n",
    "            uni.append(word)\n",
    "        if word in freqTable: \n",
    "            freqTable[word] += 1\n",
    "        else: \n",
    "            freqTable[word] = 1\n",
    "\n",
    "\n",
    "n=len(lemm_f)\n",
    "\n",
    "for word in uni:\n",
    "    idf[word]=0\n",
    "    for i in lemm_f:\n",
    "        if word in i:\n",
    "            idf[word]+=1\n",
    "for word in idf:\n",
    "    idf[word]=math.log((1+n)/idf[word])\n",
    "\n",
    "for word in freqTable:\n",
    "    freqTable[word]*=idf[word]\n",
    "\n",
    "weight=[]\n",
    "s_weight=[]\n",
    "d={}\n",
    "for i in lemm_f:\n",
    "    su=0\n",
    "    for j in i:\n",
    "        su+=freqTable[j]\n",
    "    weight.append(su)\n",
    "for i in weight:\n",
    "    s_weight.append(i)\n",
    "s_weight.sort(reverse=True)\n",
    "for i in s_weight:\n",
    "    d[i]=weight.index(i)\n",
    "\n",
    "summary = '' \n",
    "top=int(input('Enter the number of sentences in the summary: '))\n",
    "if top>len(a):\n",
    "    print('Cannot be summarised since the number of sentences entered is greater than the number of sentences in the text')\n",
    "else:\n",
    "    i=0\n",
    "    for j in s_weight:\n",
    "        if i in range(top):\n",
    "            print(a[d[j]])\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "    content = str(request.POST['lister'])\n",
    "    lang = str(request.POST['language'])\n",
    "    #if lang == \"eng\":\n",
    "        content = word_tokenize(content)\n",
    "        blank_list = []\n",
    "        stop_word = set(stopwords.words('english'))\n",
    "        sub_list = []\n",
    "        for w in content:\n",
    "            if w not in stop_word:\n",
    "                sub_list.append(w)\n",
    "                if w == '.':\n",
    "                    blank_list.append(sub_list)\n",
    "                    sub_list = []\n",
    "        final_list = []\n",
    "        for i in range(len(blank_list)):\n",
    "            sentence = str(i+1) + \". \"\n",
    "            for j in range(len(blank_list[i])):\n",
    "                sentence += blank_list[i][j]\n",
    "                sentence += \" \"\n",
    "            final_list.append(sentence)\n",
    "        return render(request, 'textlist.html', {'lists': final_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. एक किसान खेतों काम घर लौट\n",
      "2. रास्ते एक हलवाई दुकान\n",
      "3. दिन किसान ज्‍यादा काम लिया उसे भूख भी लग रही\n",
      "4. ऐसे हलवाई दुकान पास गुजरा उसे मिठाइयों खुशबू आने लगी\n",
      "5. वहां खुद रोके बिना रह पाया\n",
      "6. लेकिन दिन पास ज्यादा पैसे ऐसे मिठाई खरीद तब देर वहीं खड़े होकर मिठाइयों सुगंध आनंद लेने लगा\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "\n",
    "st=['के','का',',','में','की','है','यह','थे','ही','और','से','हैं','थी','को','पर','इस','होता','कि','जो','कर','मे','गया','करने','किया','लिये','अपने','ने','बनी','नहीं','तो','ही','या',\"एवं\",'दिया','हो','इसका','था','ही','द्वारा','हुआ','तक','साथ','करना','वाले','बाद','लिए','आप','कुछ','सकते','किसी','ये','इसके','सबसे','इसमें','थे','दो','होने','वह','वे','करते','बहुत','कहा','वर्ग','कई','करें','होती','अपनी','उनके','थी','यदि','हुई','जा','ना','इसे','कहते','जब','होते','कोई','हुए','व','न','अभी','जैसे','सभी','करता','उनकी','तरह','उस','आदि','कुल','एस','रहा','इसकी','सकता','रहे','उनका','इसी','रखें','अपना','पे','उसके']\n",
    "s='एक किसान था, वह अपने खेतों में काम कर घर लौट रहा था। रास्ते में ही एक हलवाई की दुकान थी। उस दिन किसान ने कुछ ज्‍यादा काम कर लिया था और उसे भूख भी बहुत लग रही थी। ऐसे में जब वह हलवाई की दुकान के पास से गुजरा तो उसे मिठाइयों की खुशबू आने लगी। वह वहां खुद को रोके बिना नहीं रह पाया। लेकिन उस दिन उसके पास ज्यादा पैसे नहीं थे, ऐसे में वह मिठाई खरीद नहीं सकता था, तब वह कुछ देर वहीं खड़े होकर मिठाइयों की सुगंध का आनंद लेने लगा।'\n",
    "new=[]\n",
    "ne=[]\n",
    "ovr=[]\n",
    "a=s.split('।')\n",
    "for i in a:\n",
    "    ne.append(word_tokenize(i))\n",
    "for j in ne:\n",
    "    for i in j:\n",
    "        if '।' not in i and i not in [',','?','!']:        \n",
    "            t=i\n",
    "            if t not in st:\n",
    "                new.append(i)\n",
    "    ovr.append(new)\n",
    "    new=[]\n",
    "final=[]\n",
    "for i in range(len(ovr)):\n",
    "    sentence=str(i+1)+'.'\n",
    "    for j in ovr[i]:\n",
    "        sentence+=' '\n",
    "        sentence+=j\n",
    "    final.append(sentence)\n",
    "for i in range(len(final)-1):\n",
    "    print(final[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak now for part  1\n",
      "['मेरा नाम छवि है मैं 8:00 बजे उठी हूं ', ' मैं यह भूल गई']\n",
      "मेरा नाम छवि है मैं 8:00 बजे उठी हूं ।  मैं यह भूल गई। \n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import os \n",
    "import pyttsx3\n",
    "\n",
    "r=sr.Recognizer()\n",
    "mic=sr.Microphone()\n",
    "\n",
    "c=0\n",
    "i=1\n",
    "with mic as source:\n",
    "    r.adjust_for_ambient_noise(source, duration=2)\n",
    "    print('speak now for part ',i)\n",
    "    audio=r.listen(source)\n",
    "    MyText = r.recognize_google(audio, language='hi-IN') \n",
    "    MyText = MyText.lower()\n",
    "    i+=1\n",
    "\n",
    "s=''\n",
    "MyText=MyText.split('विराम')\n",
    "print(MyText)\n",
    "for i in MyText:\n",
    "    s+=i\n",
    "    s+='। '\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
